{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The RGB to Lab color transformations were translated from scikit image's rgb2lab and lab2rgb.\n",
    "\n",
    "https://github.com/scikit-image/scikit-image/blob/a48bf6774718c64dade4548153ae16065b595ca9/skimage/color/colorconv.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from .rgb import linear_rgb_to_rgb, rgb_to_linear_rgb\n",
    "from .xyz import rgb_to_xyz, xyz_to_rgb\n",
    "\n",
    "\n",
    "def rgb_to_lab(image: torch.Tensor) -> torch.Tensor:\n",
    "    r\"\"\"Convert a RGB image to Lab.\n",
    "\n",
    "    .. image:: _static/img/rgb_to_lab.png\n",
    "\n",
    "    The input RGB image is assumed to be in the range of :math:`[0, 1]`. Lab\n",
    "    color is computed using the D65 illuminant and Observer 2.\n",
    "\n",
    "    Args:\n",
    "        image: RGB Image to be converted to Lab with shape :math:`(*, 3, H, W)`.\n",
    "\n",
    "    Returns:\n",
    "        Lab version of the image with shape :math:`(*, 3, H, W)`.\n",
    "        The L channel values are in the range 0..100. a and b are in the range -128..127.\n",
    "\n",
    "    Example:\n",
    "        >>> input = torch.rand(2, 3, 4, 5)\n",
    "        >>> output = rgb_to_lab(input)  # 2x3x4x5\n",
    "    \"\"\"\n",
    "    if not isinstance(image, torch.Tensor):\n",
    "        raise TypeError(f\"Input type is not a torch.Tensor. Got {type(image)}\")\n",
    "\n",
    "    if len(image.shape) < 3 or image.shape[-3] != 3:\n",
    "        raise ValueError(f\"Input size must have a shape of (*, 3, H, W). Got {image.shape}\")\n",
    "\n",
    "    # Convert from sRGB to Linear RGB\n",
    "    lin_rgb = rgb_to_linear_rgb(image)\n",
    "\n",
    "    xyz_im: torch.Tensor = rgb_to_xyz(lin_rgb)\n",
    "\n",
    "    # normalize for D65 white point\n",
    "    xyz_ref_white = torch.tensor([0.95047, 1.0, 1.08883], device=xyz_im.device, dtype=xyz_im.dtype)[..., :, None, None]\n",
    "    xyz_normalized = torch.div(xyz_im, xyz_ref_white)\n",
    "\n",
    "    threshold = 0.008856\n",
    "    power = torch.pow(xyz_normalized.clamp(min=threshold), 1 / 3.0)\n",
    "    scale = 7.787 * xyz_normalized + 4.0 / 29.0\n",
    "    xyz_int = torch.where(xyz_normalized > threshold, power, scale)\n",
    "\n",
    "    x: torch.Tensor = xyz_int[..., 0, :, :]\n",
    "    y: torch.Tensor = xyz_int[..., 1, :, :]\n",
    "    z: torch.Tensor = xyz_int[..., 2, :, :]\n",
    "\n",
    "    L: torch.Tensor = (116.0 * y) - 16.0\n",
    "    a: torch.Tensor = 500.0 * (x - y)\n",
    "    _b: torch.Tensor = 200.0 * (y - z)\n",
    "\n",
    "    out: torch.Tensor = torch.stack([L, a, _b], dim=-3)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def lab_to_rgb(image: torch.Tensor, clip: bool = True) -> torch.Tensor:\n",
    "    r\"\"\"Convert a Lab image to RGB.\n",
    "\n",
    "    The L channel is assumed to be in the range of :math:`[0, 100]`.\n",
    "    a and b channels are in the range of :math:`[-128, 127]`.\n",
    "\n",
    "    Args:\n",
    "        image: Lab image to be converted to RGB with shape :math:`(*, 3, H, W)`.\n",
    "        clip: Whether to apply clipping to insure output RGB values in range :math:`[0, 1]`.\n",
    "\n",
    "    Returns:\n",
    "        Lab version of the image with shape :math:`(*, 3, H, W)`.\n",
    "        The output RGB image are in the range of :math:`[0, 1]`.\n",
    "\n",
    "    Example:\n",
    "        >>> input = torch.rand(2, 3, 4, 5)\n",
    "        >>> output = lab_to_rgb(input)  # 2x3x4x5\n",
    "    \"\"\"\n",
    "    if not isinstance(image, torch.Tensor):\n",
    "        raise TypeError(f\"Input type is not a torch.Tensor. Got {type(image)}\")\n",
    "\n",
    "    if len(image.shape) < 3 or image.shape[-3] != 3:\n",
    "        raise ValueError(f\"Input size must have a shape of (*, 3, H, W). Got {image.shape}\")\n",
    "\n",
    "    L: torch.Tensor = image[..., 0, :, :]\n",
    "    a: torch.Tensor = image[..., 1, :, :]\n",
    "    _b: torch.Tensor = image[..., 2, :, :]\n",
    "\n",
    "    fy = (L + 16.0) / 116.0\n",
    "    fx = (a / 500.0) + fy\n",
    "    fz = fy - (_b / 200.0)\n",
    "\n",
    "    # if color data out of range: Z < 0\n",
    "    fz = fz.clamp(min=0.0)\n",
    "\n",
    "    fxyz = torch.stack([fx, fy, fz], dim=-3)\n",
    "\n",
    "    # Convert from Lab to XYZ\n",
    "    power = torch.pow(fxyz, 3.0)\n",
    "    scale = (fxyz - 4.0 / 29.0) / 7.787\n",
    "    xyz = torch.where(fxyz > 0.2068966, power, scale)\n",
    "\n",
    "    # For D65 white point\n",
    "    xyz_ref_white = torch.tensor([0.95047, 1.0, 1.08883], device=xyz.device, dtype=xyz.dtype)[..., :, None, None]\n",
    "    xyz_im = xyz * xyz_ref_white\n",
    "\n",
    "    rgbs_im: torch.Tensor = xyz_to_rgb(xyz_im)\n",
    "\n",
    "    # https://github.com/richzhang/colorization-pytorch/blob/66a1cb2e5258f7c8f374f582acc8b1ef99c13c27/util/util.py#L107\n",
    "    #     rgbs_im = torch.where(rgbs_im < 0, torch.zeros_like(rgbs_im), rgbs_im)\n",
    "\n",
    "    # Convert from RGB Linear to sRGB\n",
    "    rgb_im = linear_rgb_to_rgb(rgbs_im)\n",
    "\n",
    "    # Clip to 0,1 https://www.w3.org/Graphics/Color/srgb\n",
    "    if clip:\n",
    "        rgb_im = torch.clamp(rgb_im, min=0.0, max=1.0)\n",
    "\n",
    "    return rgb_im\n",
    "\n",
    "\n",
    "class RgbToLab(nn.Module):\n",
    "    r\"\"\"Convert an image from RGB to Lab.\n",
    "\n",
    "    The image data is assumed to be in the range of :math:`[0, 1]`. Lab\n",
    "    color is computed using the D65 illuminant and Observer 2.\n",
    "\n",
    "    Returns:\n",
    "        Lab version of the image.\n",
    "\n",
    "    Shape:\n",
    "        - image: :math:`(*, 3, H, W)`\n",
    "        - output: :math:`(*, 3, H, W)`\n",
    "\n",
    "    Examples:\n",
    "        >>> input = torch.rand(2, 3, 4, 5)\n",
    "        >>> lab = RgbToLab()\n",
    "        >>> output = lab(input)  # 2x3x4x5\n",
    "\n",
    "    Reference:\n",
    "        [1] https://docs.opencv.org/4.0.1/de/d25/imgproc_color_conversions.html\n",
    "\n",
    "        [2] https://www.easyrgb.com/en/math.php\n",
    "\n",
    "        [3] https://github.com/torch/image/blob/dc061b98fb7e946e00034a5fc73e883a299edc7f/generic/image.c#L1467\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        return rgb_to_lab(image)\n",
    "\n",
    "\n",
    "class LabToRgb(nn.Module):\n",
    "    r\"\"\"Convert an image from Lab to RGB.\n",
    "\n",
    "    Returns:\n",
    "        RGB version of the image. Range may not be in :math:`[0, 1]`.\n",
    "\n",
    "    Shape:\n",
    "        - image: :math:`(*, 3, H, W)`\n",
    "        - output: :math:`(*, 3, H, W)`\n",
    "\n",
    "    Examples:\n",
    "        >>> input = torch.rand(2, 3, 4, 5)\n",
    "        >>> rgb = LabToRgb()\n",
    "        >>> output = rgb(input)  # 2x3x4x5\n",
    "\n",
    "    References:\n",
    "        [1] https://docs.opencv.org/4.0.1/de/d25/imgproc_color_conversions.html\n",
    "\n",
    "        [2] https://www.easyrgb.com/en/math.php\n",
    "\n",
    "        [3] https://github.com/torch/image/blob/dc061b98fb7e946e00034a5fc73e883a299edc7f/generic/image.c#L1518\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, image: torch.Tensor, clip: bool = True) -> torch.Tensor:\n",
    "        return lab_to_rgb(image, clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a978a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00ef72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
