{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c237b3ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrgb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear_rgb_to_rgb, rgb_to_linear_rgb\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxyz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rgb_to_xyz, xyz_to_rgb\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrgb_to_luv\u001b[39m(image: torch\u001b[38;5;241m.\u001b[39mTensor, eps: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "\"\"\"The RGB to Luv color transformations were translated from scikit image's rgb2luv and luv2rgb.\n",
    "\n",
    "https://github.com/scikit-image/scikit-image/blob/a48bf6774718c64dade4548153ae16065b595ca9/skimage/color/colorconv.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from .rgb import linear_rgb_to_rgb, rgb_to_linear_rgb\n",
    "from .xyz import rgb_to_xyz, xyz_to_rgb\n",
    "\n",
    "\n",
    "def rgb_to_luv(image: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:\n",
    "    r\"\"\"Convert a RGB image to Luv.\n",
    "\n",
    "    .. image:: _static/img/rgb_to_luv.png\n",
    "\n",
    "    The image data is assumed to be in the range of :math:`[0, 1]`. Luv\n",
    "    color is computed using the D65 illuminant and Observer 2.\n",
    "\n",
    "    Args:\n",
    "        image: RGB Image to be converted to Luv with shape :math:`(*, 3, H, W)`.\n",
    "        eps: for numerically stability when dividing.\n",
    "\n",
    "    Returns:\n",
    "        Luv version of the image with shape :math:`(*, 3, H, W)`.\n",
    "\n",
    "    Example:\n",
    "        >>> input = torch.rand(2, 3, 4, 5)\n",
    "        >>> output = rgb_to_luv(input)  # 2x3x4x5\n",
    "    \"\"\"\n",
    "    if not isinstance(image, torch.Tensor):\n",
    "        raise TypeError(f\"Input type is not a torch.Tensor. Got {type(image)}\")\n",
    "\n",
    "    if len(image.shape) < 3 or image.shape[-3] != 3:\n",
    "        raise ValueError(f\"Input size must have a shape of (*, 3, H, W). Got {image.shape}\")\n",
    "\n",
    "    # Convert from sRGB to Linear RGB\n",
    "    lin_rgb = rgb_to_linear_rgb(image)\n",
    "\n",
    "    xyz_im: torch.Tensor = rgb_to_xyz(lin_rgb)\n",
    "\n",
    "    x: torch.Tensor = xyz_im[..., 0, :, :]\n",
    "    y: torch.Tensor = xyz_im[..., 1, :, :]\n",
    "    z: torch.Tensor = xyz_im[..., 2, :, :]\n",
    "\n",
    "    threshold = 0.008856\n",
    "    L: torch.Tensor = torch.where(y > threshold, 116.0 * torch.pow(y.clamp(min=threshold), 1.0 / 3.0) - 16.0, 903.3 * y)\n",
    "\n",
    "    # Compute reference white point\n",
    "    xyz_ref_white: Tuple[float, float, float] = (0.95047, 1.0, 1.08883)\n",
    "    u_w: float = (4 * xyz_ref_white[0]) / (xyz_ref_white[0] + 15 * xyz_ref_white[1] + 3 * xyz_ref_white[2])\n",
    "    v_w: float = (9 * xyz_ref_white[1]) / (xyz_ref_white[0] + 15 * xyz_ref_white[1] + 3 * xyz_ref_white[2])\n",
    "\n",
    "    u_p: torch.Tensor = (4 * x) / (x + 15 * y + 3 * z + eps)\n",
    "    v_p: torch.Tensor = (9 * y) / (x + 15 * y + 3 * z + eps)\n",
    "\n",
    "    u: torch.Tensor = 13 * L * (u_p - u_w)\n",
    "    v: torch.Tensor = 13 * L * (v_p - v_w)\n",
    "\n",
    "    out = torch.stack([L, u, v], dim=-3)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def luv_to_rgb(image: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:\n",
    "    r\"\"\"Convert a Luv image to RGB.\n",
    "\n",
    "    Args:\n",
    "        image: Luv image to be converted to RGB with shape :math:`(*, 3, H, W)`.\n",
    "        eps: for numerically stability when dividing.\n",
    "\n",
    "    Returns:\n",
    "        Luv version of the image with shape :math:`(*, 3, H, W)`.\n",
    "\n",
    "    Example:\n",
    "        >>> input = torch.rand(2, 3, 4, 5)\n",
    "        >>> output = luv_to_rgb(input)  # 2x3x4x5\n",
    "    \"\"\"\n",
    "    if not isinstance(image, torch.Tensor):\n",
    "        raise TypeError(f\"Input type is not a torch.Tensor. Got {type(image)}\")\n",
    "\n",
    "    if len(image.shape) < 3 or image.shape[-3] != 3:\n",
    "        raise ValueError(f\"Input size must have a shape of (*, 3, H, W). Got {image.shape}\")\n",
    "\n",
    "    L: torch.Tensor = image[..., 0, :, :]\n",
    "    u: torch.Tensor = image[..., 1, :, :]\n",
    "    v: torch.Tensor = image[..., 2, :, :]\n",
    "\n",
    "    # Convert from Luv to XYZ\n",
    "    y: torch.Tensor = torch.where(L > 7.999625, torch.pow((L + 16) / 116, 3.0), L / 903.3)\n",
    "\n",
    "    # Compute white point\n",
    "    xyz_ref_white: Tuple[float, float, float] = (0.95047, 1.0, 1.08883)\n",
    "    u_w: float = (4 * xyz_ref_white[0]) / (xyz_ref_white[0] + 15 * xyz_ref_white[1] + 3 * xyz_ref_white[2])\n",
    "    v_w: float = (9 * xyz_ref_white[1]) / (xyz_ref_white[0] + 15 * xyz_ref_white[1] + 3 * xyz_ref_white[2])\n",
    "\n",
    "    a: torch.Tensor = u_w + u / (13 * L + eps)\n",
    "    d: torch.Tensor = v_w + v / (13 * L + eps)\n",
    "    c: torch.Tensor = 3 * y * (5 * d - 3)\n",
    "\n",
    "    z: torch.Tensor = ((a - 4) * c - 15 * a * d * y) / (12 * d + eps)\n",
    "    x: torch.Tensor = -(c / (d + eps) + 3.0 * z)\n",
    "\n",
    "    xyz_im: torch.Tensor = torch.stack([x, y, z], -3)\n",
    "\n",
    "    rgbs_im: torch.Tensor = xyz_to_rgb(xyz_im)\n",
    "\n",
    "    # Convert from RGB Linear to sRGB\n",
    "    rgb_im = linear_rgb_to_rgb(rgbs_im)\n",
    "\n",
    "    return rgb_im\n",
    "\n",
    "\n",
    "class RgbToLuv(nn.Module):\n",
    "    r\"\"\"Convert an image from RGB to Luv.\n",
    "\n",
    "    The image data is assumed to be in the range of :math:`[0, 1]`. Luv\n",
    "    color is computed using the D65 illuminant and Observer 2.\n",
    "\n",
    "    Returns:\n",
    "        Luv version of the image.\n",
    "\n",
    "    Shape:\n",
    "        - image: :math:`(*, 3, H, W)`\n",
    "        - output: :math:`(*, 3, H, W)`\n",
    "\n",
    "    Examples:\n",
    "        >>> input = torch.rand(2, 3, 4, 5)\n",
    "        >>> luv = RgbToLuv()\n",
    "        >>> output = luv(input)  # 2x3x4x5\n",
    "\n",
    "    Reference:\n",
    "        [1] https://docs.opencv.org/4.0.1/de/d25/imgproc_color_conversions.html\n",
    "\n",
    "        [2] https://www.easyrgb.com/en/math.php\n",
    "\n",
    "        [3] http://www.poynton.com/ColorFAQ.html\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        return rgb_to_luv(image)\n",
    "\n",
    "\n",
    "class LuvToRgb(nn.Module):\n",
    "    r\"\"\"Convert an image from Luv to RGB.\n",
    "\n",
    "    Returns:\n",
    "        RGB version of the image.\n",
    "\n",
    "    Shape:\n",
    "        - image: :math:`(*, 3, H, W)`\n",
    "        - output: :math:`(*, 3, H, W)`\n",
    "\n",
    "    Examples:\n",
    "        >>> input = torch.rand(2, 3, 4, 5)\n",
    "        >>> rgb = LuvToRgb()\n",
    "        >>> output = rgb(input)  # 2x3x4x5\n",
    "\n",
    "    References:\n",
    "        [1] https://docs.opencv.org/4.0.1/de/d25/imgproc_color_conversions.html\n",
    "\n",
    "        [2] https://www.easyrgb.com/en/math.php\n",
    "\n",
    "        [3] http://www.poynton.com/ColorFAQ.html\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        return luv_to_rgb(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57500927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
