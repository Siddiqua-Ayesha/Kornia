{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddeb13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CFA(Enum):\n",
    "    r\"\"\"Define the configuration of the color filter array.\n",
    "\n",
    "    So far only bayer images is supported and the enum sets the pixel order for bayer. Note that this can change due\n",
    "    to things like rotations and cropping of images. Take care if including the translations in pipeline.\n",
    "    This implementations is optimized to be reasonably fast, look better than simple nearest neighbour.\n",
    "    On top of this care is taken to make it reversible going raw -> rgb -> raw. the raw samples remain intact\n",
    "    during conversion and only unknown samples are interpolated.\n",
    "\n",
    "    The names are based on the OpenCV convention where the BG indicates pixel 1,1 (counting from 0,0) is\n",
    "    blue and its neighbour to the right is green. In that case the top left pixel is red. Other options are GB, RG and\n",
    "    GR\n",
    "\n",
    "    reference:\n",
    "        https://en.wikipedia.org/wiki/Color_filter_array\n",
    "    \"\"\"\n",
    "\n",
    "    BG = 0\n",
    "    GB = 1\n",
    "    RG = 2\n",
    "    GR = 3\n",
    "\n",
    "\n",
    "def raw_to_rgb(image: torch.Tensor, cfa: CFA) -> torch.Tensor:\n",
    "    r\"\"\"Convert a raw bayer image to RGB version of image.\n",
    "\n",
    "    We are assuming a CFA with 2 green, 1 red, 1 blue. A bilinear interpolation is used for R/G and a fix convolution\n",
    "    for the green pixels. To simplify calculations we expect the Height Width to be evenly divisible by 2.\n",
    "\n",
    "    The image data is assumed to be in the range of (0, 1). Image H/W is assumed to be evenly divisible by 2.\n",
    "    for simplicity reasons\n",
    "\n",
    "    Args:\n",
    "        image: raw image to be converted to RGB with shape :math:`(*,1,H,W)`.\n",
    "        cfa: The configuration of the color filter.\n",
    "    Returns:\n",
    "        RGB version of the image with shape :math:`(*,3,H,W)`.\n",
    "\n",
    "    Example:\n",
    "        >>> rawinput = torch.randn(2, 1, 4, 6)\n",
    "        >>> rgb = raw_to_rgb(rawinput, CFA.RG) # 2x3x4x6\n",
    "    \"\"\"\n",
    "    if not isinstance(image, torch.Tensor):\n",
    "        raise TypeError(f\"Input type is not a torch.Tensor. \" f\"Got {type(image)}\")\n",
    "\n",
    "    if image.dim() < 3 or image.size(-3) != 1:\n",
    "        raise ValueError(f\"Input size must have a shape of (*, 1, H, W). \" f\"Got {image.shape}.\")\n",
    "\n",
    "    if len(image.shape) < 2 or image.shape[-2] % 2 == 1 or image.shape[-1] % 2 == 1:\n",
    "        raise ValueError(f\"Input H&W must be evenly disible by 2. Got {image.shape}\")\n",
    "\n",
    "    imagesize = image.size()\n",
    "\n",
    "    image = image.view(-1, 1, image.shape[-2], image.shape[-1])\n",
    "\n",
    "    # BG is defined as pel 1,1 being blue, that is the top left is actually green. This matches\n",
    "    # opencv naming so makes sense to keep\n",
    "    if cfa == CFA.BG:\n",
    "        r = image[..., :, ::2, ::2]\n",
    "        b = image[..., :, 1::2, 1::2]\n",
    "        rpad = (0, 1, 0, 1)\n",
    "        bpad = (1, 0, 1, 0)\n",
    "    elif cfa == CFA.GB:\n",
    "        r = image[..., :, ::2, 1::2]\n",
    "        b = image[..., :, 1::2, ::2]\n",
    "        rpad = (1, 0, 0, 1)\n",
    "        bpad = (0, 1, 1, 0)\n",
    "    elif cfa == CFA.RG:\n",
    "        r = image[..., :, 1::2, 1::2]\n",
    "        b = image[..., :, ::2, ::2]\n",
    "        rpad = (1, 0, 1, 0)\n",
    "        bpad = (0, 1, 0, 1)\n",
    "    elif cfa == CFA.GR:\n",
    "        r = image[..., :, 1::2, ::2]\n",
    "        b = image[..., :, ::2, 1::2]\n",
    "        rpad = (0, 1, 1, 0)\n",
    "        bpad = (1, 0, 0, 1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported CFA \" f\"Got {cfa}.\")\n",
    "\n",
    "    # upscaling r and b with bi-linear gives reasonable quality\n",
    "    # Note that depending on where these are sampled we need to pad appropriately\n",
    "    # the bilinear filter will pretty much be based on for example this layout (RG)\n",
    "    # (which needs to be padded bottom right)\n",
    "    # +-+-+\n",
    "    # |B| |\n",
    "    # | | |\n",
    "    # +-+-+\n",
    "    # While in this layout we need to pad with additional B samples top left to\n",
    "    # make sure we interpolate from the correct position\n",
    "    # +-+-+\n",
    "    # | | |\n",
    "    # | |B|\n",
    "    # +-+-+\n",
    "    # For an image like this (3x2 blue pixels)\n",
    "    # +------+\n",
    "    # |B B B |\n",
    "    # |      |\n",
    "    # |B B B |\n",
    "    # |      |\n",
    "    # +------+\n",
    "    # It needs to be expanded to this (4x3 pixels scaled to 7x5 for correct interpolation)\n",
    "    # +-------+\n",
    "    # |B B B b|\n",
    "    # |       |\n",
    "    # |B B B b|\n",
    "    # |       |\n",
    "    # |b b b b|\n",
    "    # +-------+\n",
    "    # and we crop the area afterwards. This is since the interpolation will be between first and last pixel\n",
    "    # evenly spaced between them while the B/R samples will be missing in the corners were they are assumed to exist\n",
    "    # Further we need to do align_corners to start the interpolation from the middle of the samples in the corners, that\n",
    "    # way we get to keep the known blue samples across the whole image\n",
    "    rpadded = torch.nn.functional.pad(r, list(rpad), 'replicate')\n",
    "    bpadded = torch.nn.functional.pad(b, list(bpad), 'replicate')\n",
    "    # use explicit padding instead of conv2d padding to be able to use reflect which mirror the correct colors\n",
    "    # for a 2x2 bayer filter\n",
    "    gpadded = torch.nn.functional.pad(image, [1, 1, 1, 1], 'reflect')\n",
    "\n",
    "    r_up = torch.nn.functional.interpolate(\n",
    "        rpadded, size=(image.shape[-2] + 1, image.shape[-1] + 1), mode='bilinear', align_corners=True\n",
    "    )\n",
    "    b_up = torch.nn.functional.interpolate(\n",
    "        bpadded, size=(image.shape[-2] + 1, image.shape[-1] + 1), mode='bilinear', align_corners=True\n",
    "    )\n",
    "\n",
    "    # remove the extra padding\n",
    "    r_up = torch.nn.functional.pad(r_up, [-x for x in rpad])\n",
    "    b_up = torch.nn.functional.pad(b_up, [-x for x in bpad])\n",
    "\n",
    "    # all unknown pixels are the average of the nearby green samples\n",
    "    kernel = torch.tensor(\n",
    "        [[[[0.0, 0.25, 0.0], [0.25, 0.0, 0.25], [0.0, 0.25, 0.0]]]], dtype=image.dtype, device=image.device\n",
    "    )\n",
    "\n",
    "    # This is done on all samples but result for the known green samples is then overwritten by the input\n",
    "    g_up = torch.nn.functional.conv2d(gpadded, kernel)\n",
    "\n",
    "    # overwrite the already known samples which otherwise have values from r/b\n",
    "    # this depends on the CFA configuration\n",
    "    if cfa == CFA.BG:\n",
    "        g_up[:, :, ::2, 1::2] = image[:, :, ::2, 1::2]\n",
    "        g_up[:, :, 1::2, ::2] = image[:, :, 1::2, ::2]\n",
    "    elif cfa == CFA.GB:\n",
    "        g_up[:, :, ::2, ::2] = image[:, :, ::2, ::2]\n",
    "        g_up[:, :, 1::2, 1::2] = image[:, :, 1::2, 1::2]\n",
    "    elif cfa == CFA.RG:\n",
    "        g_up[:, :, 1::2, ::2] = image[:, :, 1::2, ::2]\n",
    "        g_up[:, :, ::2, 1::2] = image[:, :, ::2, 1::2]\n",
    "    elif cfa == CFA.GR:\n",
    "        g_up[:, :, 1::2, 1::2] = image[:, :, 1::2, 1::2]\n",
    "        g_up[:, :, ::2, ::2] = image[:, :, ::2, ::2]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported CFA \" f\"Got {cfa}.\")\n",
    "\n",
    "    r_up = r_up.view(imagesize)\n",
    "    g_up = g_up.view(imagesize)\n",
    "    b_up = b_up.view(imagesize)\n",
    "\n",
    "    rgb: torch.Tensor = torch.cat([r_up, g_up, b_up], dim=-3)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def rgb_to_raw(image: torch.Tensor, cfa: CFA) -> torch.Tensor:\n",
    "    r\"\"\"Convert a RGB image to RAW version of image with the specified color filter array.\n",
    "\n",
    "    The image data is assumed to be in the range of (0, 1).\n",
    "\n",
    "    Args:\n",
    "        image: RGB image to be converted to bayer raw with shape :math:`(*,3,H,W)`.\n",
    "        cfa: Which color filter array do we want the output to mimic. I.e. which pixels are red/green/blue.\n",
    "\n",
    "    Returns:\n",
    "        raw version of the image with shape :math:`(*,1,H,W)`.\n",
    "\n",
    "    Example:\n",
    "        >>> rgbinput = torch.rand(2, 3, 4, 6)\n",
    "        >>> raw = rgb_to_raw(rgbinput, CFA.BG) # 2x1x4x6\n",
    "    \"\"\"\n",
    "    if not isinstance(image, torch.Tensor):\n",
    "        raise TypeError(f\"Input type is not a torch.Tensor. Got {type(image)}\")\n",
    "\n",
    "    if len(image.shape) < 3 or image.shape[-3] != 3:\n",
    "        raise ValueError(f\"Input size must have a shape of (*, 3, H, W). Got {image.shape}\")\n",
    "\n",
    "    # pick the tensor with green pixels\n",
    "    # clone to make sure grad works\n",
    "    output: torch.Tensor = image[..., 1:2, :, :].clone()\n",
    "\n",
    "    # overwrite the r/b positions (depending on the cfa configuration) with blue/red pixels\n",
    "    if cfa == CFA.BG:\n",
    "        output[..., :, ::2, ::2] = image[..., 0:1, ::2, ::2]  # red\n",
    "        output[..., :, 1::2, 1::2] = image[..., 2:3, 1::2, 1::2]  # blue\n",
    "    elif cfa == CFA.GB:\n",
    "        output[..., :, ::2, 1::2] = image[..., 0:1, ::2, 1::2]  # red\n",
    "        output[..., :, 1::2, ::2] = image[..., 2:3, 1::2, ::2]  # blue\n",
    "    elif cfa == CFA.RG:\n",
    "        output[..., :, 1::2, 1::2] = image[..., 0:1, 1::2, 1::2]  # red\n",
    "        output[..., :, ::2, ::2] = image[..., 2:3, ::2, ::2]  # blue\n",
    "    elif cfa == CFA.GR:\n",
    "        output[..., :, 1::2, ::2] = image[..., 0:1, 1::2, ::2]  # red\n",
    "        output[..., :, ::2, 1::2] = image[..., 2:3, ::2, 1::2]  # blue\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class RawToRgb(nn.Module):\n",
    "    r\"\"\"Module to convert a bayer raw image to RGB version of image.\n",
    "\n",
    "    The image data is assumed to be in the range of (0, 1).\n",
    "\n",
    "    Shape:\n",
    "        - image: :math:`(*, 1, H, W)`\n",
    "        - output: :math:`(*, 3, H, W)`\n",
    "\n",
    "    Example:\n",
    "        >>> rawinput = torch.rand(2, 1, 4, 6)\n",
    "        >>> rgb = RawToRgb(CFA.RG)\n",
    "        >>> output = rgb(rawinput)  # 2x3x4x5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfa: CFA) -> None:\n",
    "        super().__init__()\n",
    "        self.cfa = cfa\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        return raw_to_rgb(image, cfa=self.cfa)\n",
    "\n",
    "\n",
    "class RgbToRaw(nn.Module):\n",
    "    r\"\"\"Module to convert a RGB image to bayer raw version of image.\n",
    "\n",
    "    The image data is assumed to be in the range of (0, 1).\n",
    "\n",
    "    Shape:\n",
    "        - image: :math:`(*, 3, H, W)`\n",
    "        - output: :math:`(*, 1, H, W)`\n",
    "\n",
    "    reference:\n",
    "        https://docs.opencv.org/4.0.1/de/d25/imgproc_color_conversions.html\n",
    "\n",
    "    Example:\n",
    "        >>> rgbinput = torch.rand(2, 3, 4, 6)\n",
    "        >>> raw = RgbToRaw(CFA.GB)\n",
    "        >>> output = raw(rgbinput)  # 2x1x4x6\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfa: CFA) -> None:\n",
    "        super().__init__()\n",
    "        self.cfa = cfa\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        return rgb_to_raw(image, cfa=self.cfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54936b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
